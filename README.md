# ğŸ“Š MarketMinds

**An AI-powered financial chatbot that answers complex market and company-related questions by combining real financial data with company reports using Retrieval-Augmented Generation (RAG).**

Think of it as a junior financial analyst that never gets tired.

---

## ğŸš€ What It Does

MarketMinds allows users to ask natural language questions like:

- *"How did Apple perform in its last earnings call?"*
- *"Summarize the key risks mentioned in Tesla's annual report."*
- *"Compare Infosys and TCS based on recent financials."*

The system intelligently decides whether to:

- Fetch live/structured market data
- Search company reports (PDFs)
- Combine both to generate a grounded, context-aware response

---

## ğŸ§  Architecture

```
User Query
   â†“
Intent Detection (API / Reports / Hybrid)
   â†“
Data Retrieval (Stock API or Vector DB)
   â†“
LLM + Context (RAG)
   â†“
Final Answer
```

The system uses:

- **Intent Router** - Determines if query needs market data, reports, or both
- **LLM Client** - Ollama-based (Mistral) for local, privacy-respecting inference
- **RAG Pipeline** - Vector embeddings + document retrieval for company reports
- **Financial Data Source** - API integration for real-time stock/market data

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Language** | Python 3.8+ |
| **Backend Framework** | FastAPI |
| **LLM** | Ollama (Mistral) |
| **Embeddings** | Sentence Transformers |
| **Vector Store** | Local (Chroma/FAISS) |
| **Frontend** | HTML/CSS/JavaScript |
| **Document Processing** | PyPDF2, LangChain |

---

## ğŸ“ Project Structure

```
marketminds-chatbot/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚       â”œâ”€â”€ config.py               # Configuration management
â”‚       â”œâ”€â”€ chatbot/
â”‚       â”‚   â”œâ”€â”€ response_builder.py # RAG pipeline orchestration
â”‚       â”‚   â””â”€â”€ router.py           # Intent routing logic
â”‚       â”œâ”€â”€ data_sources/
â”‚       â”‚   â””â”€â”€ financial_api.py    # External data integrations
â”‚       â”œâ”€â”€ llm/
â”‚       â”‚   â”œâ”€â”€ llm_client.py       # Ollama client
â”‚       â”‚   â””â”€â”€ prompt_templates.py # LLM prompts
â”‚       â”œâ”€â”€ rag/
â”‚       â”‚   â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚       â”‚   â”œâ”€â”€ ingest.py           # Document ingestion
â”‚       â”‚   â””â”€â”€ retriever.py        # Vector search & retrieval
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ pdf_utils.py        # PDF parsing
â”‚           â””â”€â”€ text_utils.py       # Text processing
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                  # Chat interface
â”‚   â”œâ”€â”€ app.js                      # Frontend logic
â”‚   â””â”€â”€ style.css                   # Styling
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw documents
â”‚   â”œâ”€â”€ processed/                  # Processed data (CSVs)
â”‚   â””â”€â”€ vector_store/               # Vector embeddings store
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_basic_flow.py          # Integration tests
â””â”€â”€ notebooks/
    â””â”€â”€ experiments.ipynb           # Development & prototyping
```

---

## âš™ï¸ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- [Ollama](https://ollama.ai) installed and running locally
- pip package manager

### 1. Clone & Navigate

```bash
git clone <your-repo-url>
cd marketminds-chatbot
```

### 2. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up Ollama

```bash
# Start Ollama service (runs on localhost:11434)
ollama serve

# In another terminal, pull the Mistral model
ollama pull mistral
```

### 5. Prepare Data

Place earnings reports and company documents in `data/raw/` directory.

Run the ingestion pipeline:

```bash
python backend/app/rag/ingest.py
```

This will:
- Process PDFs
- Generate embeddings
- Store vectors in `data/vector_store/`

---

## ğŸƒ Running the Application

### Start the Backend

```bash
cd marketminds-chatbot
uvicorn backend.app.main:app --reload
```

The API will be available at `http://localhost:8000`

- **Chat endpoint**: `POST /query`
- **Health check**: `GET /health`
- **API docs**: `http://localhost:8000/docs`

### Access the Frontend

Open your browser and navigate to:

```
http://localhost:8000
```

---

## ğŸ“– Usage Examples

### Via Chat Interface

Simply type your questions:

```
"What were Tesla's revenue and profit margins last quarter?"
"Which tech stocks are mentioned positively in recent earnings?"
"Summarize the risks disclosed by Meta"
```

### Via API

```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"question": "How did Apple perform in Q3?"}'
```

Response:

```json
{
  "answer": "Based on Apple's Q3 earnings report..."
}
```

---

## ğŸ§ª Testing

Run the test suite:

```bash
pytest tests/ -v
```

---

## ğŸ¯ Why MarketMinds?

Most financial tools analyze one data source at a time. **MarketMinds**:

âœ… Combines structured + unstructured financial data  
âœ… Performs cross-source reasoning  
âœ… Abstracts complex workflows into one simple question  
âœ… Mirrors how real financial analysts think  

---

## ğŸ“Œ Current Status

- âœ… Core architecture designed & implemented
- âœ… FastAPI backend with RAG pipeline
- âœ… Ollama LLM integration
- âœ… Vector store setup
- âœ… Basic chat interface
- ğŸ”„ In development: Enhanced intent detection, multi-company analysis

---

## ğŸ”® Future Improvements

- ğŸ“° News integration & sentiment analysis
- ğŸ”„ Multi-company comparisons
- ğŸ“Š Advanced financial ratio analysis
- ğŸ¤– Multi-agent architecture for complex queries
- ğŸ“± Mobile-friendly interface
- ğŸ” User authentication & session management

---

## ğŸ› ï¸ Development

### Code Structure

- **`chatbot/`** - Core reasoning and response generation
- **`data_sources/`** - External data integrations
- **`llm/`** - Language model interface
- **`rag/`** - Retrieval-augmented generation pipeline
- **`utils/`** - Helper utilities

### Adding New Features

1. Create feature branch: `git checkout -b feature/your-feature`
2. Implement in appropriate module
3. Add tests in `tests/`
4. Submit pull request

---

## ğŸ“ Configuration

Edit `backend/app/config.py` to customize:

- Model selection (default: Mistral)
- Data directories
- API endpoints
- Debug mode

---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| Ollama connection refused | Ensure Ollama is running: `ollama serve` |
| Model not found | Pull model: `ollama pull mistral` |
| Port 8000 in use | Change port: `uvicorn ... --port 8001` |
| Vector store empty | Run: `python backend/app/rag/ingest.py` |

---

## ğŸ“„ License

This project is open source and available under the MIT License.

---

## ğŸ‘¤ Author

**Abhay Shinde**  
Computer Engineering Student | Data & AI Enthusiast

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to:

- Report bugs
- Suggest features
- Submit pull requests
- Improve documentation

---

## ğŸ“š Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [Ollama Models](https://ollama.ai/library)
- [LangChain Documentation](https://langchain.readthedocs.io)
- [Vector Search Basics](https://www.pinecone.io/learn/vector-search)

---

**Built with â¤ï¸ for financial data exploration**
